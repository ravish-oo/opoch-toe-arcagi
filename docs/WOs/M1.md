# Milestone M1 — “Canvas online” (v1.6; after WO-02 + WO-14 + WO-04a)

## Purpose

Bring the **working canvas** online deterministically. The runner computes a **single output size** ((R_{\text{out}},C_{\text{out}})) from trainings (H1–H7), logs full receipts, and stops. No painting, no normalization, no selection yet.

> Note: This **replaces** the old LCM step. Delete any LCM code/receipts. There is **no** downscale at M1.

---

## Preconditions (frozen)

* **WO-02** PERIOD (proper KMP p≥2) ✅
* **WO-05** Components (for WO-14 features) ✅
* **WO-14** Features & Size Predictor (H1–H7, frozen order + tie rules) ✅
* **WO-04a** Working canvas provider (calls WO-14 early) ✅
* **WO-03** Frames already integrated at M0 ✅

---

## Runner contract (src/arcbit/runner.py) — M1 delta

```python
def solve(task_json) -> (Y_placeholder, receipts_bundle):
    # M0 sections (unchanged)
    C = color_universe(task_json)
    pack_unpack_identity_for_all_grids(...)
    frames_in, frames_out = canonicalize_inputs_outputs(...)
    apply_pose_anchor_equivalence_on_Xstar(...)

    # NEW at M1: Working canvas (no LCM)
    # 1) Compute features for each training input (WO-14)
    features = [agg_features(X_i, C_order) for each training X_i]  # integers only

    # 2) Choose working canvas using trainings only (WO-04a)
    R_out, C_out, size_fit_receipts = choose_working_canvas(train_pairs, frames_in, frames_out, xstar_shape)

    # 3) Add 'working_canvas' section to receipts (embed size_fit_receipts)
    #    Do not normalize any grid to (R_out,C_out) at M1.

    # Return placeholder Y (still X*), plus full receipts
    return X_star, receipts_bundle
```

**Strictly remove:** any `normalization/lcm_canvas`, `downscale_strict`, `lcm_shape` fields. They no longer exist.

---

## Receipts (first-class; additive; stable)

Add **one** new section; keep all M0 sections unchanged.

* **`working_canvas`** (from WO-04a):

  * `features_hash_per_training`: list of BLAKE3 hashes of each training’s FeatureVector
  * `attempts`: ordered H1–H7 attempts with params, ok_train_ids, fit_all
  * `winner`: `{family:"Hk", params:{...}}` (if any)
  * `R_out`, `C_out` (integers)
  * `verified_train_ids`: all training ids
  * `section_hash`

**Do not** break existing receipt keys; this section is additive.

---

## Invariants (must hold)

* **Trainings-only**: no test leakage for hypothesis selection.
* **Single working canvas**: exactly one ((R_{\text{out}},C_{\text{out}})) if a fit exists. No LCM.
* **Frozen hypothesis order and bounds** (H1..H7) with frozen tie-rule (min test-area, then family id, then param lex).
* **Determinism**: double-run identical section hashes.

---

## Failure modes (explicit)

* **`SIZE_UNDETERMINED`** (fail-closed) if no H1–H7 fits **all** trainings. The runner must:

  * Return error status + receipts with the full `attempts` trail and a `first_counterexample` showing which training size didn’t match which hypothesis.
* No UNSAT/AC-3/selection errors at M1; those appear in later milestones.

---

## What to delete/avoid (from old M1)

* **LCM-lift** and **post-solve downscale**: removed.
* Any `lcm_shape`, `upscale_hash`, `reduce_*` receipts.
* Any content normalization at M1. Only size selection + receipts.

---

## Reviewer quick-verification (real ARC; 1–2 lines)

* Pick tasks where training outputs differ in size; `working_canvas` must produce a **single** `(R_out,C_out)` and an ordered `attempts` trail with a clear winner; **no** LCM fields anywhere.

---

## Developer checklist (Implementer)

* Remove any LCM codepaths from runner; wire **only** `agg_features` + `choose_working_canvas`.
* Do **not** normalize (Y_i) or (X^*) to ((R_{\text{out}},C_{\text{out}})) at M1.
* Emit `working_canvas` section exactly as WO-04a specifies; keep M0 sections identical.
* Enforce double-run receipts equality.

---

## Minimal “pass through” verification for M1 (for the reviewer)

* Sweep a curated mixed-size subset (or all 1000): the runner returns `X*` and **always** includes `working_canvas` receipts; any failure is **only** `SIZE_UNDETERMINED` with a clear attempts trail and counterexample; M0 sections unchanged.

This gives you a clean, deterministic M1 that’s fully aligned with v1.6 and keeps the evolving runner predictable.
